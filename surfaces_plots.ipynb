{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymskt.mesh import Mesh\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from pymskt.image import read_nrrd\n",
    "from pymskt.mesh.meshTransform import SitkVtkTransformer\n",
    "from pymskt.mesh.meshTools import ProbeVtkImageDataAlongLine\n",
    "from pymskt.mesh.meshTools import get_surface_normals, n2l, l2n\n",
    "from pymskt.mesh.utils import is_hit, get_intersect, get_surface_normals, get_obb_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_subject_data(subject_file_names):\n",
    "\n",
    "    '''\n",
    "    function which takes in a list of all the subject file names and creates a nested dictionary with \n",
    "    'Subject_number', 'VISIT-NUMBER' and 'knee type' (injured or contralateral) for each subject\n",
    "    '''\n",
    "\n",
    "    subject_numbers= []\n",
    "    for file in subject_file_names:\n",
    "        subject_numbers.append(file[-35:-31])\n",
    "    \n",
    "    # remove duplicate numbers and sort in ascending order\n",
    "    subject_numbers= list(set(subject_numbers))\n",
    "    subject_numbers.sort()\n",
    "\n",
    "    # dictionary with subject number, visit number and knee file names\n",
    "    subject_data={}\n",
    "\n",
    "    for index, subject_number in enumerate(subject_numbers):\n",
    "\n",
    "        # collect all the files for each subject\n",
    "        subject_data[subject_number] = [file for file in subject_file_names if file[-35:-31] == subject_number]\n",
    "        \n",
    "        # define a new dictioary, visit, whose keys are 'VISIT-1', 'VISIT-2', 'VISIT-3','VISIT-4', and 'VISIT-5'       \n",
    "        visit={}\n",
    "\n",
    "        for visit_number in range(5):\n",
    "\n",
    "            # key = VISIT-X\n",
    "            key= f'VISIT-{visit_number+1}'\n",
    "\n",
    "            # collect all the files for each visit\n",
    "            visit[key]= [file for file in subject_data[subject_number] if key in file]\n",
    "\n",
    "            # define a new dictioary knee, whose keys are ' injured' and 'contralateral'\n",
    "            knee= {} \n",
    "\n",
    "            if len(visit[key])==2: # check if each visit has 2 files (for injured and contralateral)\n",
    "                \n",
    "                if subject_number == '24-P' and key == 'VISIT-1': # exception case\n",
    "\n",
    "                    # the higher exam number is the contralateral knee\n",
    "                    if visit[key][0][-5:] < visit[key][1][-5:]: \n",
    "                        knee['injured'] = visit[key][1]\n",
    "                        knee['contralateral'] = visit[key][0]\n",
    "                    else:\n",
    "                        knee['injured'] = visit[key][0]\n",
    "                        knee['contralateral'] = visit[key][1]\n",
    "                \n",
    "                else:\n",
    "\n",
    "                    # the higher exam number is the injured knee and the other contralateral\n",
    "                    if visit[key][0][-5:] < visit[key][1][-5:]: \n",
    "                        knee['injured'] = visit[key][0]\n",
    "                        knee['contralateral'] = visit[key][1]\n",
    "                    else:\n",
    "                        knee['injured'] = visit[key][1]\n",
    "                        knee['contralateral'] = visit[key][0]\n",
    "\n",
    "            elif len(visit[key])==1:\n",
    "                knee['NA'] = visit[key][0]\n",
    "        \n",
    "            visit[key]= knee\n",
    "\n",
    "        subject_data[subject_number] = visit\n",
    "\n",
    "         # remove 'VISIT-X' if there is no scan\n",
    "        subject_data[subject_number]= {k: v for k, v in subject_data[subject_number].items() if v}\n",
    "\n",
    "    return subject_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['DIR']= '/dataNAS/people/anoopai/DESS_ACL_study'\n",
    "os.environ['DATA']= 'data_processed'\n",
    "os.environ['LOG']= 'notebooks_dosma_registration_pipeline/logs'\n",
    "os.environ['FILES']= 'notebooks_dosma_registration_pipeline/files'\n",
    "os.environ['RESULTS']= 'results'\n",
    "\n",
    "# Change working directory to the directory containing data\n",
    "dir_path = os.environ['DIR']\n",
    "log_path= (os.path.join(os.environ['DIR'], os.environ['LOG']))\n",
    "file_path= (os.path.join(os.environ['DIR'], os.environ['FILES']))\n",
    "data_dir_path = (os.path.join(os.environ['DIR'], os.environ['DATA']))\n",
    "results_path = (os.path.join(os.environ['DIR'], os.environ['RESULTS']))\n",
    "os.chdir(data_dir_path)\n",
    "\n",
    "# Get list of all folders (patient-visit-leg) in the data directory\n",
    "os.chdir(data_dir_path)\n",
    "dirs = os.listdir(data_dir_path)\n",
    "dirs = [item for item in dirs if 'stdout.nipype' not in item]\n",
    "dirs = [item for item in dirs if '.nfs00' not in item]\n",
    "\n",
    "# Get directory names and categorise them as Patient or Control\n",
    "subject_files=[]\n",
    "patient_file_names=[]\n",
    "control_file_names=[]\n",
    "\n",
    "for index, dir in enumerate(dirs):\n",
    "    # sub_dirs= aa= '\\t'.join(os.listdir(dir)) # joins all the element of the list using \\t chracter (white space)\n",
    "\n",
    "    # if \"Sag_DESS_HR_OneTouch15660-3132-p\" in os.listdir(dir): # check if qDESS file exists in the folder : RAW FILES ONLY\n",
    "    if \"results\" in os.listdir(dir):\n",
    "        \n",
    "        # list with all the useful files (which contains segmentations)\n",
    "        subject_files.append(dir)\n",
    "\n",
    "        if '-P-' in dir:\n",
    "            patient_file_names.append(dir)\n",
    "        elif '-C-' in dir:\n",
    "            control_file_names.append(dir)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    patient_file_names.sort()\n",
    "    control_file_names.sort()\n",
    "\n",
    "    patient_data= categorize_subject_data(patient_file_names)\n",
    "    control_data= categorize_subject_data(control_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan0 = patient_data['27-P']['VISIT-1']['injured']\n",
    "scan1 = patient_data['27-P']['VISIT-3']['injured']\n",
    "\n",
    "seg_mask_type= 'dosma' \n",
    "status='reg2baseline' #'reg2timepoint'\n",
    "quant_type= 't2' #'t1_rho'\n",
    "cluster_type= 'pos' # 'neg']\n",
    "data_name= f'{quant_type}_{status}_{seg_mask_type}'\n",
    "\n",
    "timepoint0 = os.path.join(data_dir_path, scan0)\n",
    "timepoint1 = os.path.join(data_dir_path, scan1)\n",
    "\n",
    "fc_path0 = os.path.join(timepoint0, f'results/{data_name}/fc/fc.nii.gz')\n",
    "t2_path0 = os.path.join(timepoint0, f'results/{data_name}/fc/{quant_type}/{quant_type}_filtered.nii.gz')\n",
    "fc_path1 = os.path.join(timepoint1, f'results/{data_name}/fc/fc.nii.gz')\n",
    "t2_path1 = os.path.join(timepoint1, f'results/{data_name}/fc/{quant_type}/{quant_type}_filtered.nii.gz')\n",
    "diff_maps_path = os.path.join(timepoint1, f'results/cluster_analysis/{data_name}/difference_maps.nii.gz')\n",
    "intensity_thresh_path = os.path.join(timepoint1, f'results/cluster_analysis/{data_name}/difference_maps_intensity_threshold_{cluster_type}.nii.gz')\n",
    "volume_thresh_path = os.path.join(timepoint1, f'results/cluster_analysis/{data_name}/cluster_{cluster_type}_all/fc/{quant_type}/{quant_type}.nii.gz')\n",
    "\n",
    "fc_save_path0 = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/fc0.nrrd')\n",
    "t2_save_path0 = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/t20.nrrd')\n",
    "fc_save_path1 = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/fc1.nrrd')\n",
    "t2_save_path1 = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/t21.nrrd')\n",
    "diff_maps_save_path = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/diff_maps.nrrd')\n",
    "intensity_thresh_save_path = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/intensity_threshold.nrrd')\n",
    "volume_thresh_save_path = os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/volume_threshold.nrrd')\n",
    "\n",
    "t2_3D_save_path0= os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/t20.vtk')\n",
    "t2_3D_save_path1= os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/t21.vtk')\n",
    "diff_maps_3D_save_path= os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/diff_maps.vtk')\n",
    "intensity_thresh_3D_save_path= os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/intensity_threshold.vtk')\n",
    "volume_thresh_3D_save_path= os.path.join(results_path, f'difference_maps/cluster_results_all/surface_plot_data/volume_threhsold.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To apply this pipeline to other data, you will need to:\n",
    "1. change fc_path to be the appropriate segmentation file\n",
    "2. change t2_path to whatever you want to use for analysis. E.g.\n",
    "    - difference_maps.nii\n",
    "    - pre or post T2\n",
    "    - cluster maps\n",
    "    - etc.\n",
    "\"\"\"\n",
    "fc0 = sitk.ReadImage(fc_path0)\n",
    "sitk.WriteImage(fc0, fc_save_path0)\n",
    "\n",
    "t20 = sitk.ReadImage(t2_path0)\n",
    "sitk.WriteImage(t20, t2_save_path0)\n",
    "\n",
    "fc1 = sitk.ReadImage(fc_path1)\n",
    "sitk.WriteImage(fc1, fc_save_path1)\n",
    "\n",
    "t21 = sitk.ReadImage(t2_path1)\n",
    "sitk.WriteImage(t21, t2_save_path1)\n",
    "\n",
    "diff_maps= sitk.ReadImage(diff_maps_path)\n",
    "sitk.WriteImage(diff_maps, diff_maps_save_path)\n",
    "\n",
    "intensity_thresh= sitk.ReadImage(intensity_thresh_path)\n",
    "sitk.WriteImage(intensity_thresh, intensity_thresh_save_path)\n",
    "\n",
    "volume_thresh= sitk.ReadImage(volume_thresh_path)\n",
    "sitk.WriteImage(volume_thresh, volume_thresh_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_surace_plot(t2_path, fc_path, save_path):\n",
    "     \n",
    "    import os\n",
    "    from pymskt.mesh import Mesh\n",
    "    import SimpleITK as sitk\n",
    "    import numpy as np\n",
    "\n",
    "    from pymskt.image import read_nrrd\n",
    "    from pymskt.mesh.meshTransform import SitkVtkTransformer\n",
    "    from pymskt.mesh.meshTools import ProbeVtkImageDataAlongLine\n",
    "    from pymskt.mesh.meshTools import get_surface_normals, n2l, l2n\n",
    "    from pymskt.mesh.utils import is_hit, get_intersect, get_surface_normals, get_obb_surface\n",
    "        \n",
    "    # Create a surface mesh from the segmentation file. \n",
    "\n",
    "    # smooth_image_var will dicatate how smooth the surface is\n",
    "    # if parts of the surface are missing, try decreasing this value. \n",
    "    # if it appears to jagged, try increasing this value.\n",
    "\n",
    "    mesh = Mesh(path_seg_image=fc_path, label_idx=1)\n",
    "    mesh.create_mesh(smooth_image_var=0.2)\n",
    "\n",
    "    # resample surface will reduce the number of points in the mesh\n",
    "    # and separate them equally over the surface. \n",
    "    mesh.resample_surface(clusters=10000)\n",
    "\n",
    "    # read the t2 image data in sitk. \n",
    "    sitk_image = sitk.ReadImage(t2_path)\n",
    "\n",
    "    # read the t2 image data in vtk. - set origin to zero so that its at the origin\n",
    "    # it doesnt account for rotations (now) and so easiest to align with the mesh\n",
    "    # by undoing its translation, and then undoing rotation & translation for the mesh\n",
    "    nrrd_t2 = read_nrrd(t2_path, set_origin_zero=True).GetOutput()\n",
    "\n",
    "    # apply inverse transform to the mesh (so its also at the origin)\n",
    "    nrrd_transformer = SitkVtkTransformer(sitk_image)\n",
    "    mesh.apply_transform_to_mesh(transform=nrrd_transformer.get_inverse_transform())\n",
    "\n",
    "    # setup the probe that we are using to get data from the T2 file \n",
    "    line_resolution = 10000   # number of points along the line that the T2 data is sampled at\n",
    "    filler = 0              # if no data is found, what value to fill the data with\n",
    "    ray_length= -10          # how far to extend the ray from the surface (using negative to go inwards/towards the other side)\n",
    "    percent_ray_length_opposite_direction = 1.0  # extend the other way a % of the line to make sure get both edges. 1.0 = 100%|\n",
    "\n",
    "    data_probe = ProbeVtkImageDataAlongLine(\n",
    "        line_resolution,\n",
    "        nrrd_t2,\n",
    "        save_mean=True,         # if we want mean. \n",
    "        save_max=True,          # if we want max\n",
    "        save_std=False,         # if we want to see variation in the data along the line. \n",
    "        save_most_common=False, # for segmentations - to show the regions on the surface. \n",
    "        filler=filler\n",
    "    )\n",
    "\n",
    "    # get the points and normals from the mesh - this is what we'll iterate over to apply the probe to. \n",
    "    points = mesh.mesh.GetPoints()\n",
    "    normals = get_surface_normals(mesh.mesh)\n",
    "    point_normals = normals.GetOutput().GetPointData().GetNormals()\n",
    "\n",
    "    # create an bounding box that we can query for intersections.\n",
    "    obb_cartilage = get_obb_surface(mesh.mesh)\n",
    "\n",
    "    # iterate over the points & their normals. \n",
    "    for idx in range(points.GetNumberOfPoints()):\n",
    "        # for each point get its x,y,z and normal\n",
    "        point = points.GetPoint(idx)\n",
    "        normal = point_normals.GetTuple(idx)\n",
    "\n",
    "        # get the start/end of the ray that we are going to use to probe the data.\n",
    "        # this is based on the ray length info defind above. \n",
    "        end_point_ray = n2l(l2n(point) + ray_length*l2n(normal))\n",
    "        start_point_ray = n2l(l2n(point) + ray_length*percent_ray_length_opposite_direction*(-l2n(normal)))\n",
    "\n",
    "        # get the number of intersections and the cell ids that intersect.\n",
    "        points_intersect, cell_ids_intersect = get_intersect(obb_cartilage, start_point_ray, end_point_ray)\n",
    "\n",
    "        # if 2 intersections (the inside/outside of the cartilage) then probe along the line between these\n",
    "        # intersections. Otherwise, fill the data with the filler value.\n",
    "        if len(points_intersect) == 2:\n",
    "            # use the intersections, not the ray length info\n",
    "            # this makes sure we only get values inside of the surface. \n",
    "            start = np.asarray(points_intersect[0])\n",
    "            end = np.asarray(points_intersect[1])\n",
    "\n",
    "            start = start + (start-end) * 0.1\n",
    "            end = end + (end-start) * 0.1\n",
    "            data_probe.save_data_along_line(start_pt=start,\n",
    "                                            end_pt=end)\n",
    "        else:\n",
    "            data_probe.append_filler()\n",
    "\n",
    "    # undo the transforms from above so that the mesh is put back to its original position.\n",
    "    mesh.reverse_all_transforms()\n",
    "\n",
    "    mesh.set_scalar('t2_max', data_probe.max_data)\n",
    "    mesh.set_scalar('t2_mean', data_probe.mean_data)\n",
    "    mesh.save_mesh(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_surace_plot(t2_save_path0, fc_save_path0, t2_3D_save_path0)\n",
    "create_surace_plot(t2_save_path1, fc_save_path1, t2_3D_save_path1)\n",
    "create_surace_plot(diff_maps_save_path, fc_save_path1, diff_maps_3D_save_path)\n",
    "create_surace_plot(intensity_thresh_save_path, fc_save_path1, intensity_thresh_3D_save_path)\n",
    "create_surace_plot(volume_thresh_save_path, fc_save_path1, volume_thresh_3D_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
